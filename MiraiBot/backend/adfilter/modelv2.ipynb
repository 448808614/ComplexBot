{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ok\n"
    }
   ],
   "source": [
    "#%%\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "185\n72\n"
    }
   ],
   "source": [
    "allNormalText = open(r\"./data/data-normal.txt\", 'r', encoding='utf-8').read()\n",
    "allNormalTextArray = allNormalText.split('\\n')\n",
    "print(len(allNormalTextArray))\n",
    "\n",
    "allAdText = open(r\"./data/data-pssisterad.txt\", 'r', encoding='utf-8').read()\n",
    "allAdTextArray = allAdText.split('\\n')\n",
    "print(len(allAdTextArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from the default dictionary ...\nLoading model from cache C:\\Users\\Kenvix\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 0.760 seconds.\nPrefix dict has been built successfully.\n257\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[['没有', '上次', '学长', '学姐', '教', '几节课'],\n ['学姐', '交', '一下'],\n ['认识', '学姐', '保研'],\n ['党明', '学姐', '真的', '强'],\n ['想不到', '没有', '党明', '学姐', '做', '不到'],\n ['党明', '学姐'],\n ['党明', '学姐', '献上'],\n ['学姐'],\n ['我见', '证明', '党明', '学姐', '非常', '漂亮', '女孩子'],\n ['开机', '慢点', '还好']]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from model import AdPredictor\n",
    "adp = AdPredictor()\n",
    "splitNormalWords = [list(adp.splitWords(ad, False)) for ad in allNormalTextArray+allAdTextArray]\n",
    "print(len(splitNormalWords))\n",
    "splitNormalWords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "None\n[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)], [(2, 1), (6, 1), (7, 1)], [(2, 1), (8, 1), (9, 1)], [(2, 1), (10, 1), (11, 1), (12, 1)], [(2, 1), (5, 1), (10, 1), (13, 1), (14, 1), (15, 1)], [(2, 1), (10, 1)], [(2, 1), (10, 1), (16, 1)], [(2, 1)], [(2, 1), (10, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)], [(22, 1), (23, 1), (24, 1)]]\n"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "# 赋给语料库中每个词(不重复的词)一个整数id\n",
    "dictionary = corpora.Dictionary(splitNormalWords)\n",
    "new_corpus = [dictionary.doc2bow(text) for text in splitNormalWords]\n",
    "print(dictionary.get(\"学姐\"))\n",
    "print(new_corpus[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[(0, 0.4602581128821097), (1, 0.4602581128821097), (2, 0.23564377058789043), (3, 0.4602581128821097), (4, 0.4602581128821097), (5, 0.31164385360202146)], [(2, 0.42981837308890347), (6, 0.5249204813955685), (7, 0.7346527440680071)], [(2, 0.3595264199034269), (8, 0.7022250201784704), (9, 0.6145085633469818)], [(2, 0.3217561308178781), (10, 0.44617781992931005), (11, 0.6284522998805557), (12, 0.5499509542305356)], [(2, 0.29056380361078027), (5, 0.3842767549025883), (10, 0.40292355616001396), (13, 0.36851110907890555), (14, 0.3842767549025883), (15, 0.56752761843906)]]\n2\n153\n上次\n"
    }
   ],
   "source": [
    "from gensim import models\n",
    "tfidf = models.TfidfModel(new_corpus)\n",
    "tfidf.save(\"tfidf.gsm\")\n",
    "\n",
    "# 使用这个训练好的模型得到单词的tfidf值\n",
    "tfidf_vec = []\n",
    "tfidf_vocabs = []\n",
    "for i in range(len(splitNormalWords)):\n",
    "    string_bow = dictionary.doc2bow(splitNormalWords[i])\n",
    "    string_tfidf = tfidf[string_bow]\n",
    "    tfidf_vec.append(string_tfidf)\n",
    "\n",
    "print(tfidf_vec[0:5])\n",
    "tfidf_vocabs_word_to_id = dictionary.token2id\n",
    "print(tfidf_vocabs_word_to_id.get(\"学姐\"))\n",
    "print(tfidf_vocabs_word_to_id.get(\"大佬\"))\n",
    "# print(tfidf_vocabs)\n",
    "tfidf_vocabs = {value:key for (key, value) in tfidf_vocabs_word_to_id.items()}\n",
    "print(tfidf_vocabs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "257\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "02,  3.94364332e-03,\n        -2.35571848e-02, -1.75726012e-02,  2.17364642e-03,\n        -2.51707859e-02],\n       [-2.75715130e-02, -1.60476701e-03, -4.39499937e-02,\n         7.87939500e-03,  1.18300632e-02, -6.92914276e-03,\n        -2.55796808e-02,  1.09308553e-03,  1.47001833e-02,\n        -2.90677029e-02],\n       [-2.48834897e-02, -1.43868237e-02, -4.02918613e-03,\n         1.89338568e-02,  1.31068082e-02, -5.44056862e-03,\n        -1.00856926e-02, -5.98123942e-03, -5.97891209e-03,\n         5.55390323e-03],\n       [-5.85340248e-03,  8.95757513e-03, -1.32620822e-02,\n         5.96175297e-03,  2.70497179e-02, -1.20213917e-02,\n        -1.93209308e-02, -3.14607639e-04, -4.72602641e-03,\n         6.92828413e-03],\n       [-2.48834911e-02, -1.43868239e-02, -4.02918636e-03,\n         1.89338580e-02,  1.31068087e-02, -5.44056893e-03,\n        -1.00856934e-02, -5.98123965e-03, -5.97891160e-03,\n         5.55390369e-03],\n       [-2.48834912e-02, -1.43868245e-02, -4.02918665e-03,\n         1.89338572e-02,  1.31068085e-02, -5.44056857e-03,\n        -1.00856937e-02, -5.98123936e-03, -5.97891102e-03,\n         5.55390108e-03],\n       [-2.75715124e-02, -1.60476693e-03, -4.39499952e-02,\n         7.87939504e-03,  1.18300635e-02, -6.92914240e-03,\n        -2.55796816e-02,  1.09308551e-03,  1.47001827e-02,\n        -2.90677026e-02],\n       [-2.48834917e-02, -1.43868255e-02, -4.02918592e-03,\n         1.89338584e-02,  1.31068092e-02, -5.44056882e-03,\n        -1.00856934e-02, -5.98123982e-03, -5.97891293e-03,\n         5.55390395e-03],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [-5.71021014e-03,  1.17299704e-02,  2.29654501e-02,\n         2.22436681e-02, -4.45911907e-02,  2.46748484e-02,\n         4.94015740e-02,  1.89113967e-02, -4.09604978e-02,\n         4.10408697e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.31096277e-02, -1.00883486e-02,  3.82593968e-03,\n        -2.81704956e-02,  2.05417103e-02,  2.83430559e-02,\n         1.87861732e-02,  2.03049915e-02, -3.95002725e-02,\n         3.28176353e-02],\n       [ 2.31096256e-02, -1.00883483e-02,  3.82594010e-03,\n        -2.81704948e-02,  2.05417106e-02,  2.83430557e-02,\n         1.87861728e-02,  2.03049917e-02, -3.95002721e-02,\n         3.28176344e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [-1.23755537e-03,  2.26157058e-02, -1.38802759e-02,\n        -1.36352439e-02, -2.23302720e-02, -1.53487049e-02,\n        -5.88028259e-03, -4.10873934e-03, -1.18549705e-02,\n        -1.49382565e-02],\n       [-3.13062359e-02, -1.13982340e-02,  2.01074976e-02,\n         4.40797484e-02, -3.58327241e-03,  8.63878115e-03,\n         1.65642665e-02, -2.79037441e-02,  1.21588941e-02,\n         1.56192259e-02],\n       [-5.76539736e-03, -2.26590088e-02, -2.40083454e-02,\n        -2.28641183e-03, -1.89813411e-02,  2.07692271e-02,\n        -1.95389414e-03,  2.69325741e-02,  2.80821997e-02,\n         3.64452348e-02],\n       [ 2.65963522e-02,  4.38435082e-03,  2.86247370e-02,\n         7.42554010e-03,  1.16852311e-02, -4.55513086e-02,\n         3.32175361e-02,  1.43850461e-02,  7.07209668e-03,\n         3.52389872e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.88841796e-02,  2.31822497e-02, -1.23220188e-02,\n        -4.77555228e-02, -5.17672427e-03, -3.25640012e-02,\n        -4.55465274e-02, -3.43529749e-02, -1.27481959e-02,\n         3.05283335e-03],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 4.54712906e-02,  3.53680998e-02,  2.25577969e-02,\n        -1.77559245e-02, -4.20208712e-02, -3.82525711e-02,\n         1.97877795e-02,  3.75306429e-02, -4.52412276e-02,\n         3.83763658e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 4.54712899e-02,  3.53681015e-02,  2.25577982e-02,\n        -1.77559250e-02, -4.20208713e-02, -3.82525723e-02,\n         1.97877802e-02,  3.75306434e-02, -4.52412267e-02,\n         3.83763655e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [-4.11950096e-02,  5.75465729e-03, -3.12243949e-02,\n        -5.29544967e-03, -1.46087166e-02,  7.09690439e-03,\n        -1.66306179e-02,  1.76444586e-02,  9.64583442e-03,\n         2.18122025e-02],\n       [ 2.50909593e-02,  3.54230569e-02,  3.51979474e-02,\n        -1.66972580e-02,  3.68494667e-05, -3.64605914e-02,\n         3.33961638e-02,  1.96338097e-02, -7.38435400e-03,\n         1.18143117e-02],\n       [ 1.97051110e-03,  1.77855760e-03, -1.96075559e-02,\n         4.64692620e-03, -2.35214434e-02,  3.07590537e-03,\n        -1.30942604e-02, -3.50193490e-02, -9.53796404e-03,\n         2.00217315e-02],\n       [-1.23755537e-03,  2.26157058e-02, -1.38802759e-02,\n        -1.36352439e-02, -2.23302720e-02, -1.53487049e-02,\n        -5.88028259e-03, -4.10873934e-03, -1.18549705e-02,\n        -1.49382565e-02],\n       [-3.13062359e-02, -1.13982340e-02,  2.01074976e-02,\n         4.40797484e-02, -3.58327241e-03,  8.63878115e-03,\n         1.65642665e-02, -2.79037441e-02,  1.21588941e-02,\n         1.56192259e-02],\n       [ 5.87714624e-03, -1.29298231e-02, -5.07293884e-03,\n         1.20758380e-03, -7.94866022e-03, -3.09041126e-03,\n         1.06994654e-02,  2.24184437e-02,  2.05235537e-02,\n         3.60112722e-02],\n       [ 2.13247651e-02,  3.58819539e-02,  2.19420188e-02,\n         1.96647688e-02,  3.70191292e-02,  8.23746312e-03,\n        -4.24411939e-03, -1.63966697e-02,  1.40478636e-02,\n        -2.29962728e-03],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.50272978e-02,  2.38378785e-02, -1.06312242e-03,\n         3.84000033e-02, -5.03765913e-02,  4.57489790e-02,\n        -4.58891423e-02,  1.67266267e-02,  6.51815603e-03,\n         5.17494930e-02],\n       [ 6.95733172e-03, -2.19680246e-03, -1.70368876e-02,\n        -2.57290520e-02, -4.87385584e-02,  2.07603846e-02,\n        -4.14747713e-03,  3.03698158e-03, -4.82232894e-02,\n         1.19260654e-02],\n       [ 3.56144722e-02, -1.12715459e-02, -4.70022185e-02,\n         2.88863421e-02, -2.74558969e-02,  2.07637091e-02,\n         7.07304084e-03, -5.26583996e-03,  8.49608388e-03,\n        -3.13341333e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [-3.57289483e-02,  3.26171013e-02,  4.65602414e-02,\n        -6.11524904e-03, -4.22368890e-02, -4.35664821e-02,\n         1.10304061e-03,  1.16111776e-02,  4.28066173e-02,\n         3.36550604e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.31096256e-02, -1.00883483e-02,  3.82594010e-03,\n        -2.81704948e-02,  2.05417106e-02,  2.83430557e-02,\n         1.87861728e-02,  2.03049917e-02, -3.95002721e-02,\n         3.28176344e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.70915649e-02,  2.19213234e-02,  4.63779887e-02,\n        -2.79904832e-02,  4.45379813e-02,  4.88749736e-02,\n         6.80997116e-03, -2.53938753e-02, -4.52467365e-02,\n        -4.86001027e-02],\n       [-3.57289447e-02,  3.26170980e-02,  4.65602394e-02,\n        -6.11524896e-03, -4.22368845e-02, -4.35664802e-02,\n         1.10304048e-03,  1.16111771e-02,  4.28066123e-02,\n         3.36550569e-02],\n       [ 2.70915664e-02,  2.19213226e-02,  4.63779897e-02,\n        -2.79904846e-02,  4.45379824e-02,  4.88749733e-02,\n         6.80997147e-03, -2.53938756e-02, -4.52467397e-02,\n        -4.86001033e-02],\n       [ 9.61391008e-03,  1.00060353e-02,  4.35658213e-03,\n        -2.60942247e-02,  5.41754501e-03,  1.31959367e-02,\n         1.15716401e-02,  8.65495391e-03, -2.11842558e-02,\n         3.37218482e-03],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 6.95115810e-03,  2.82184868e-03, -1.62398065e-02,\n        -1.26390181e-02,  1.81890312e-02,  1.01837594e-02,\n         1.05014680e-02,  1.35168960e-02, -1.79020978e-03,\n        -8.12037286e-03],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [-2.09072467e-02, -4.04400219e-02, -6.64644987e-03,\n        -3.42401579e-02, -4.23492939e-02,  6.47501701e-03,\n         1.53641592e-02,  4.50965997e-03,  5.90637085e-03,\n         1.89119945e-02],\n       [-1.34243718e-02, -3.86902080e-02,  5.86987807e-03,\n        -2.73927082e-02, -4.98134426e-02,  2.30983873e-02,\n         1.54612583e-02, -2.21132448e-02, -1.75277665e-02,\n         3.80810724e-02],\n       [-1.03716539e-02,  1.01558439e-02, -4.19509858e-02,\n        -1.59947501e-02, -2.24110785e-03,  3.63301563e-04,\n         6.72433903e-03,  9.68511436e-03, -4.34077291e-03,\n         4.97905837e-03],\n       [ 2.31096256e-02, -1.00883483e-02,  3.82594010e-03,\n        -2.81704948e-02,  2.05417106e-02,  2.83430557e-02,\n         1.87861728e-02,  2.03049917e-02, -3.95002721e-02,\n         3.28176344e-02],\n       [ 4.64061100e-03,  3.82379944e-03, -2.15382910e-02,\n        -2.74660998e-03,  1.44099899e-02,  1.46161129e-03,\n         7.77174651e-03, -7.10159213e-04, -1.74332356e-02,\n         2.88820262e-03],\n       [ 5.97463225e-03,  1.40482902e-02, -1.17059150e-02,\n         2.02579738e-03, -3.07911287e-03, -6.49470002e-03,\n        -1.12286428e-02,  1.42059728e-02, -1.26522858e-02,\n         4.00985194e-03],\n       [ 3.55627637e-03,  3.54811227e-02,  4.85540431e-02,\n        -1.55786278e-02,  4.44767396e-02, -3.45671148e-02,\n         4.77753352e-02,  7.23289281e-04,  3.26167519e-02,\n        -1.62522322e-02],\n       [ 5.53369581e-03, -3.53257475e-03, -3.61334875e-02,\n         2.43189067e-04,  5.42612901e-03, -8.15683703e-03,\n         1.00535523e-02,  6.68737812e-03,  5.82829582e-03,\n        -1.23725753e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 8.84177166e-03,  1.91519878e-02,  1.08397185e-02,\n         2.24552310e-02, -1.97264898e-02,  1.13063439e-02,\n         1.18752613e-02,  2.40926198e-02, -3.71960172e-02,\n         2.46383296e-02],\n       [ 2.31096260e-02, -1.00883484e-02,  3.82593951e-03,\n        -2.81704942e-02,  2.05417105e-02,  2.83430549e-02,\n         1.87861723e-02,  2.03049924e-02, -3.95002719e-02,\n         3.28176347e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.31096266e-02, -1.00883485e-02,  3.82593945e-03,\n        -2.81704939e-02,  2.05417099e-02,  2.83430550e-02,\n         1.87861726e-02,  2.03049916e-02, -3.95002729e-02,\n         3.28176340e-02],\n       [ 5.15164933e-03,  1.71268590e-02, -4.62916268e-03,\n        -2.07873133e-02,  1.01898061e-03, -1.77879029e-02,\n         3.34916527e-02, -4.07460255e-02, -2.46995138e-02,\n        -2.02070034e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 1.73933148e-02,  1.60541698e-02,  2.32208098e-02,\n        -3.85443557e-02, -7.47876805e-03, -1.87941769e-02,\n         1.50226112e-02, -3.88489595e-02, -1.21203679e-02,\n        -3.91492983e-02],\n       [ 1.73933148e-02,  1.60541698e-02,  2.32208098e-02,\n        -3.85443557e-02, -7.47876805e-03, -1.87941769e-02,\n         1.50226112e-02, -3.88489595e-02, -1.21203679e-02,\n        -3.91492983e-02],\n       [ 2.07214593e-02, -3.47230591e-03,  1.41742963e-02,\n        -6.03463096e-03,  9.83714216e-03, -3.21380209e-02,\n         1.69373071e-02, -3.14431354e-02, -7.64381159e-03,\n        -9.72954654e-03],\n       [ 1.97064106e-02,  7.72675709e-03, -1.89436304e-03,\n        -1.21740599e-02, -2.79602557e-02,  1.23598811e-02,\n        -2.25287232e-02,  2.85912029e-02, -9.89806465e-03,\n         1.21844646e-02],\n       [ 3.98715871e-02, -4.81016180e-03,  4.95719419e-02,\n        -4.78146890e-02, -1.04304621e-02, -1.30922358e-02,\n        -8.78221657e-03, -3.19768205e-02,  4.74276371e-03,\n        -3.38093872e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 2.31096256e-02, -1.00883483e-02,  3.82594010e-03,\n        -2.81704948e-02,  2.05417106e-02,  2.83430557e-02,\n         1.87861728e-02,  2.03049917e-02, -3.95002721e-02,\n         3.28176344e-02],\n       [-1.15150630e-02,  6.73092192e-03, -8.15804936e-03,\n        -8.29588611e-03, -1.77661413e-02, -3.70041059e-02,\n         1.38591057e-02, -4.06696805e-03,  1.73328737e-02,\n        -1.77054531e-02],\n       [-1.15150630e-02,  6.73092192e-03, -8.15804936e-03,\n        -8.29588611e-03, -1.77661413e-02, -3.70041059e-02,\n         1.38591057e-02, -4.06696805e-03,  1.73328737e-02,\n        -1.77054531e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 1.44728833e-03,  1.65191908e-02, -2.41932098e-02,\n        -2.98908619e-02, -3.54825732e-03,  6.77226164e-03,\n         4.34389032e-02, -4.51115644e-02, -3.73328910e-02,\n        -5.27523198e-03],\n       [-1.15150630e-02,  6.73092192e-03, -8.15804936e-03,\n        -8.29588611e-03, -1.77661413e-02, -3.70041059e-02,\n         1.38591057e-02, -4.06696805e-03,  1.73328737e-02,\n        -1.77054531e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00],\n       [-3.82966539e-02,  3.28004917e-02, -3.97864747e-02,\n        -3.73107089e-02, -3.75728594e-02, -9.67879979e-03,\n        -2.40821360e-02,  1.98397275e-02,  6.16016506e-03,\n         1.32205697e-02],\n       [-2.40391609e-02,  1.50636761e-02,  2.67619442e-02,\n        -3.69548590e-02, -2.59243471e-02, -1.96007703e-02,\n        -1.61599498e-02, -1.59761614e-02, -4.19915470e-02,\n         1.60143260e-02],\n       [ 2.60272571e-02, -1.82669854e-02, -8.65413866e-03,\n        -5.13300958e-03,  6.93186814e-04,  6.10955078e-03,\n         2.52989129e-02, -1.37948582e-02, -4.54115773e-02,\n         8.93103193e-03],\n       [ 1.91884867e-02,  1.32876128e-02,  3.40263289e-02,\n         4.15415823e-03,  4.61807301e-02, -1.54487513e-02,\n         2.88263759e-02, -1.04425646e-02, -5.56853627e-03,\n        -8.78370380e-03],\n       [-2.19308327e-02,  1.23071125e-02,  3.41891228e-02,\n        -2.23574525e-02, -1.05770602e-02, -3.58422132e-03,\n        -7.73614323e-03, -1.60056099e-02, -3.49655500e-02,\n         2.82955256e-02],\n       [ 2.65963510e-02,  4.38435084e-03,  2.86247362e-02,\n         7.42553995e-03,  1.16852307e-02, -4.55513065e-02,\n         3.32175342e-02,  1.43850457e-02,  7.07209670e-03,\n         3.52389840e-02],\n       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n         0.00000000e+00]])"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "def tfidf_wtd_avg_word_vectors(words,tfidf_vector,tfidf_vocabulary,model,num_features):\n",
    "    #print(\"tfidf_vector\", tfidf_vector)\n",
    "    word_tfidfs = []\n",
    "    word_tfidf_map = OrderedDict()\n",
    "\n",
    "    for (key, proba) in tfidf_vector:\n",
    "        word_tfidfs.append(proba)\n",
    "        word_tfidf_map[tfidf_vocabulary[key]] = proba\n",
    "    \n",
    "    # print(word_tfidfs)\n",
    "    # print(word_tfidf_map)\n",
    "    \n",
    "    feature_vector=np.zeros((num_features,),dtype='float64')\n",
    "    vocabulary=set(model.wv.index2word)\n",
    "    wts=0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            word_vector=model[word]\n",
    "            weighted_word_vector=word_tfidf_map[word]*word_vector\n",
    "            wts=wts+word_tfidf_map[word]\n",
    "            feature_vector=np.add(feature_vector,weighted_word_vector)\n",
    "    if wts:\n",
    "        feature_vector=np.divide(feature_vector,wts)\n",
    "    return feature_vector\n",
    "\n",
    "def tfidf_weighted_averaged_word_vectorizer(corpus,tfidf_vectors,tfidf_vocabulary,model,num_features):\n",
    "    docs_tfidfs=[(doc,doc_tfidf) for doc,doc_tfidf in zip(corpus,tfidf_vectors)]\n",
    "    features=[tfidf_wtd_avg_word_vectors(tokenized_sentence,tfidf,tfidf_vocabulary,model,num_features) for tokenized_sentence,tfidf in docs_tfidfs]\n",
    "    return np.array(features)\n",
    "\n",
    "# vec = Word2Vec(splitNormalWords,size=10,window=10,min_count=2,sample=1e-3)\n",
    "word2vec = Word2Vec(splitNormalWords, min_count=3, sample=1e-3, size=10, window=10)\n",
    "vector = tfidf_weighted_averaged_word_vectorizer(corpus=splitNormalWords, tfidf_vectors=tfidf_vec, tfidf_vocabulary=tfidf_vocabs,model=word2vec,num_features=10)\n",
    "vector = np.array(vector)\n",
    "# vec.build_vocab(splitNormalWords)\n",
    "# vec.train(splitNormalWords, total_examples=len(splitNormalWords), epochs=vec.epochs)\n",
    "# # vec.save(\"vec.gsm\")\n",
    "# vec\n",
    "print(len(vector))\n",
    "word2vec.save(\"word2vec.gsm\")\n",
    "vector[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "257\n185 72\n54 21\n75\n"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "_totalNormalSize = len(allNormalTextArray)\n",
    "_totalAdSize = len(allAdTextArray)\n",
    "actualNormalSize = _totalNormalSize\n",
    "actualAdSize = _totalAdSize\n",
    "\n",
    "y = np.concatenate((np.zeros(_totalNormalSize), np.ones(_totalAdSize)), axis=0)\n",
    "#y = (np.zeros(len(allNormalTextArray)), np.ones(len(allAdTextArray)))\n",
    "\n",
    "_i = 0\n",
    "docVector = []\n",
    "\n",
    "for v in vector:\n",
    "    mean = np.mean(v)\n",
    "\n",
    "    if mean < 0.00000001:\n",
    "        if _i >= _totalNormalSize:\n",
    "            actualAdSize -= 1\n",
    "        else:\n",
    "            actualNormalSize -= 1\n",
    "    else:\n",
    "        docVector.append(v)\n",
    "\n",
    "    _i += 1\n",
    "\n",
    "print(len(vector))\n",
    "print(_totalNormalSize, _totalAdSize)\n",
    "print(actualNormalSize, actualAdSize)\n",
    "print(len(docVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7692307692307693\n"
    }
   ],
   "source": [
    "y = np.concatenate((np.zeros(_totalNormalSize), np.ones(_totalAdSize)), axis=0)\n",
    "#y = (np.zeros(len(allNormalTextArray)), np.ones(len(allAdTextArray)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vector, y, test_size=0.10, train_size=0.90, random_state=100)\n",
    "\n",
    "svmModel = SVC()  # 使用RBF核\n",
    "svmModelRes = svmModel.fit(X_train, y_train)\n",
    "print(svmModelRes.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "257\n257\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d0646b279531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RT\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RT\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    754\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\RT\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "# y = trainer.train_model()\n",
    "y = np.concatenate((np.zeros(len(allNormalTextArray)), np.ones(len(allAdTextArray))), axis=0)\n",
    "\n",
    "print(len(y))\n",
    "print(len(vector))\n",
    "\n",
    "clf = MultinomialNB(alpha=1, fit_prior=True)\n",
    "clf.fit(vector, y)\n",
    "\n",
    "result = pd.DataFrame(vector)\n",
    "keys = []\n",
    "values = []\n",
    "\n",
    "for key, value in vector:\n",
    "    keys.append(key)\n",
    "    values.append(value)\n",
    "\n",
    "df = pd.DataFrame(data={\"key\": keys, \"value\": values})\n",
    "colnames = df.sort_values(\"value\")[\"key\"].values\n",
    "result.columns = colnames\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(textMatrix, y, test_size=0.10, random_state=100)\n",
    "print(\"Test Acc\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'0.22.1'"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (JupyerNotebook)",
   "language": "python",
   "name": "pycharm-87025479"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}